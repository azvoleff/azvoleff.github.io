---
layout: post
title: "Classifying an image with teamlucc"
description: "An overview of how to use the teamlucc package to classify a satellite image"
category: articles
tags: [R, teamlucc, remote sensing]
modified: 2014-03-19
comments: true
share: true
---

## Getting started

First load the `devtools` package, used for installing `teamlucc`. Install the 
`devtools` package if it is not already installed:

```{r}
if (!require(devtools)) install.packages('devtools')
```

Now load the teamlucc package, using `devtools` to install it from github if it 
is not yet installed.

```{r}
if (!require(teamlucc)) install_github('azvoleff/teamlucc')
```

Also load the `rgdal` package needed for reading/writing shapefiles:

```{r}
library(rgdal)
```

## Collect training data for supervised classification

The first step in the classification is putting together a training dataset. 
`teamlucc` includes a function to output a shapefile that can be used for 
collecting training data. Here we are collecting training data for the 
L5TSR_1986 raster (a portion of a 1986 Landsat 5 surface reflectance image) 
that is included with the `teamlucc` package. Use the `get_extent_polys` 
function to quickly construct a shapefile in the same coordinate system as the 
image:

```{r}
train_polys <- get_extent_polys(L5TSR_1986)
```

Add an empty field named "class_1986" to the object, and delete the extent polygon 
(because we don't need it, and just want an empty shapefile):

```{r}
train_polys$class_1986 <- '' # Add an empty column named "class_1986"
train_polys <- train_polys[-1, ] # Delete extent polygon
```

Now save the `train_polys` object to a shapefile using `writeOGR` from the `rgdal` 
package. The "." below just means "save the shapefile in the current 
directory".

```{r}
writeOGR(train_polys, ".", "training_data", "ESRI Shapefile")
```

Open the generated "training_data.shp" shapefile in a GIS program (I recommend 
[QGIS](http://www.qgis.org)) and digitize a number of polygons in each of the 
land cover classes you want to map. For this example, we will simply classify 
"Forest" and "Non-forest". For each polygon you digitize, record the cover type 
in the "class_1986" column. After digitizing a number of polygons within each 
class, save the shapefile, and load it back into R using
`train_polys <- readOGR(".", "training_data")`.

Or: (for this example) you can use the thirty training polygons included in the 
`teamlucc` package in the `L5TSR_1986_2001_training` dataset:

```{r}
train_polys <- L5TSR_1986_2001_training
```

## Classify image

First we need to extract the training data from our training image, 
for each pixel within the polygons in our `train_polys` dataset. 
`extract_training_data` will use the `training` parameter that we pass to 
determine the fraction of the training data to use in training the classifier. 
If set to 1, ALL of the training data will be used to train the classifier, 
leaving no independent data for validation. If set to a fraction (for example 
.6), then only 60% of the data (randomly selected) will be used in training, 
and 40% will be preserved as an independent sample for use in testing.

Note: Validation data should generally be collected separately from training 
data anyways, to ensure the image is randomly sampled (training data collection 
is almost never random), so in most cases I don't recommend making heavy use of 
the `training` parameter. It can be useful though in testing.

```{r}
train_data <- extract_training_data(L5TSR_1986, train_polys, 
                                    class_col="class_1986", training=.6)
```

A summary method is provided by `teamlucc` for printing summary statistics on 
training datasets:

```{r}
summary(train_data)
```

To perform the actual image classification, we will use the `classify_image` 
function:

```{r}
classification <- classify_image(L5TSR_1986, train_data)
```

To see the predicted classes, use `spplot`:

```{r, predicted_classes, fig.cap="Predicted classes"}
spplot(classification$pred_classes)
```

We can also see the class probabilities (per pixel probabilities of membership of each class):

```{r, class_probabilities, fig.cap="Predicted probabilities of each class"}
spplot(classification$pred_probs)
```

Note that we can pass the `n_cpus=2` parameter to tell 
`team_classify` to use parallel processing if we have two (or more) CPUs. Don't 
set `n_cpus` to use all of your processors unless you want R to totally take 
over your system while it runs. I usually set `n_cpus=3` when running on my 
laptop, allowing one free core (I can run four threads on my laptop) so that I 
can still check email, etc. while scripts are running.

## Accuracy assessment

```{r}
acc <- accuracy(classification$model, pop=classification$pred_classes)
summary(acc)
```
